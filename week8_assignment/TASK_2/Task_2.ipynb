{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9PjVfmFOUhz",
        "outputId": "8b6db86f-c0c9-43f5-e820-28183b4572ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h➡️ Generated 10000 records at /content/big_movies_dataset.jsonl\n",
            "➡️ Flattened data written to Parquet at /content/movies_flattened_parquet\n",
            "✅ External Parquet table 'movies_external' is ready in Spark SQL.\n",
            "+----------------+--------+--------+------------+----------+-------------+------------------+--------------------------+-----------+---------+-----------+----------+---------+----------+----------+---------+------------------------------------+----------------+-------------------+------------------------------------+---------------------------+---------------+\n",
            "|duration_minutes|genres  |movie_id|release_date|title     |director_name|director_birthdate|director_nationality      |rating_imdb|rating_rt|rating_meta|budget_usd|gross_usd|award_noms|award_wins|languages|actor_id                            |actor_name      |actor_role         |company_id                          |company_name               |company_founded|\n",
            "+----------------+--------+--------+------------+----------+-------------+------------------+--------------------------+-----------+---------+-----------+----------+---------+----------+----------+---------+------------------------------------+----------------+-------------------+------------------------------------+---------------------------+---------------+\n",
            "|103             |[Action]|1       |2009-08-11  |Send large|Jose Rhodes  |1997-11-15        |Slovakia (Slovak Republic)|6.9        |7.9      |1.5        |31082869  |40603457 |16        |2         |[ms, bs] |88a1dfc6-7fe9-41eb-8442-0d9312e21f07|Kimberly Chapman|Ecologist          |496eeab4-5634-40d2-90f2-e84d708195ee|Jackson-Mccarty            |1979-10-27     |\n",
            "|103             |[Action]|1       |2009-08-11  |Send large|Jose Rhodes  |1997-11-15        |Slovakia (Slovak Republic)|6.9        |7.9      |1.5        |31082869  |40603457 |16        |2         |[ms, bs] |88a1dfc6-7fe9-41eb-8442-0d9312e21f07|Kimberly Chapman|Ecologist          |86e96740-23d8-41d1-b3df-6211faad918c|Stephenson, White and Eaton|2015-05-16     |\n",
            "|103             |[Action]|1       |2009-08-11  |Send large|Jose Rhodes  |1997-11-15        |Slovakia (Slovak Republic)|6.9        |7.9      |1.5        |31082869  |40603457 |16        |2         |[ms, bs] |88a1dfc6-7fe9-41eb-8442-0d9312e21f07|Kimberly Chapman|Ecologist          |81f0ed2e-1244-4607-8d4e-28989815eceb|Schroeder-Case             |2011-12-18     |\n",
            "|103             |[Action]|1       |2009-08-11  |Send large|Jose Rhodes  |1997-11-15        |Slovakia (Slovak Republic)|6.9        |7.9      |1.5        |31082869  |40603457 |16        |2         |[ms, bs] |24d72d36-cdd1-4f9d-a1f1-ef3703fe104a|James Mcintyre  |Early years teacher|496eeab4-5634-40d2-90f2-e84d708195ee|Jackson-Mccarty            |1979-10-27     |\n",
            "|103             |[Action]|1       |2009-08-11  |Send large|Jose Rhodes  |1997-11-15        |Slovakia (Slovak Republic)|6.9        |7.9      |1.5        |31082869  |40603457 |16        |2         |[ms, bs] |24d72d36-cdd1-4f9d-a1f1-ef3703fe104a|James Mcintyre  |Early years teacher|86e96740-23d8-41d1-b3df-6211faad918c|Stephenson, White and Eaton|2015-05-16     |\n",
            "+----------------+--------+--------+------------+----------+-------------+------------------+--------------------------+-----------+---------+-----------+----------+---------+----------+----------+---------+------------------------------------+----------------+-------------------+------------------------------------+---------------------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Install required packages\n",
        "!pip install -q faker pyspark\n",
        "\n",
        "# 2. Imports\n",
        "import json, random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# 3. Generate a large nested JSON Lines dataset\n",
        "fake = Faker()\n",
        "NUM_RECORDS = 10_000     # adjust up/down for scale\n",
        "OUTPUT_JSONL = \"/content/big_movies_dataset.jsonl\"\n",
        "\n",
        "def random_date_str():\n",
        "    start = datetime.now() - timedelta(days=50*365)\n",
        "    return (start + timedelta(days=random.randint(0, 50*365))).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "GENRES = [\"Action\",\"Comedy\",\"Drama\",\"Horror\",\"Sci‑Fi\",\"Romance\",\"Thriller\",\"Documentary\"]\n",
        "RATING_SRCS = [\"IMDb\",\"Rotten Tomatoes\",\"Metacritic\"]\n",
        "\n",
        "with open(OUTPUT_JSONL, \"w\") as f:\n",
        "    for i in range(NUM_RECORDS):\n",
        "        rec = {\n",
        "            \"movie_id\": i+1,\n",
        "            \"title\": fake.sentence(nb_words=3).rstrip(\".\"),\n",
        "            \"release_date\": random_date_str(),\n",
        "            \"duration_minutes\": random.randint(80,180),\n",
        "            \"genres\": random.sample(GENRES, k=random.randint(1,3)),\n",
        "            \"director\": {\n",
        "                \"name\": fake.name(),\n",
        "                \"birthdate\": random_date_str(),\n",
        "                \"nationality\": fake.country()\n",
        "            },\n",
        "            \"cast\": [\n",
        "                {\"actor_id\": fake.uuid4(),\n",
        "                 \"name\": fake.name(),\n",
        "                 \"role\": fake.job()}\n",
        "                for _ in range(random.randint(2,5))\n",
        "            ],\n",
        "            \"ratings\": {src: round(random.uniform(1,10),1) for src in RATING_SRCS},\n",
        "            \"box_office\": {\n",
        "                \"budget_usd\": random.randint(1_000_000,200_000_000),\n",
        "                \"gross_usd\": random.randint(1_000_000,800_000_000)\n",
        "            },\n",
        "            \"metadata\": {\n",
        "                \"awards\": {\n",
        "                    \"nominations\": random.randint(0,20),\n",
        "                    \"wins\": random.randint(0,10)\n",
        "                },\n",
        "                \"languages\": random.sample([fake.language_code() for _ in range(10)], k=2),\n",
        "                \"production_companies\": [\n",
        "                    {\"company_id\": fake.uuid4(),\n",
        "                     \"name\": fake.company(),\n",
        "                     \"founded\": random_date_str()}\n",
        "                    for _ in range(random.randint(1,3))\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "        f.write(json.dumps(rec) + \"\\n\")\n",
        "print(f\"➡️ Generated {NUM_RECORDS} records at {OUTPUT_JSONL}\")\n",
        "\n",
        "# 4. Start a Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FlattenNestedJSON\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# 5. Read the JSON Lines file\n",
        "df = spark.read.json(OUTPUT_JSONL)\n",
        "\n",
        "# 6. Flatten nested columns\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Explode arrays to separate rows\n",
        "df_flat = (\n",
        "    df\n",
        "    .withColumn(\"director_name\",       col(\"director.name\"))\n",
        "    .withColumn(\"director_birthdate\",  col(\"director.birthdate\"))\n",
        "    .withColumn(\"director_nationality\",col(\"director.nationality\"))\n",
        "    .drop(\"director\")\n",
        "\n",
        "    .withColumn(\"rating_imdb\",         col(\"ratings.IMDb\"))\n",
        "    .withColumn(\"rating_rt\",           col(\"ratings.`Rotten Tomatoes`\"))\n",
        "    .withColumn(\"rating_meta\",         col(\"ratings.Metacritic\"))\n",
        "    .drop(\"ratings\")\n",
        "\n",
        "    .withColumn(\"budget_usd\",          col(\"box_office.budget_usd\"))\n",
        "    .withColumn(\"gross_usd\",           col(\"box_office.gross_usd\"))\n",
        "    .drop(\"box_office\")\n",
        "\n",
        "    # Awards\n",
        "    .withColumn(\"award_noms\",          col(\"metadata.awards.nominations\"))\n",
        "    .withColumn(\"award_wins\",          col(\"metadata.awards.wins\"))\n",
        "    .drop(\"metadata.awards\")\n",
        "\n",
        "    # Keep languages array as-is or explode if needed\n",
        "    .withColumn(\"languages\",           col(\"metadata.languages\"))\n",
        "\n",
        "    # Explode cast and production_companies into separate rows\n",
        "    .withColumn(\"cast_member\",         explode(col(\"cast\")))\n",
        "    .withColumn(\"actor_id\",            col(\"cast_member.actor_id\"))\n",
        "    .withColumn(\"actor_name\",          col(\"cast_member.name\"))\n",
        "    .withColumn(\"actor_role\",          col(\"cast_member.role\"))\n",
        "    .drop(\"cast_member\").drop(\"cast\")\n",
        "\n",
        "    .withColumn(\"prod_company\",        explode(col(\"metadata.production_companies\")))\n",
        "    .withColumn(\"company_id\",          col(\"prod_company.company_id\"))\n",
        "    .withColumn(\"company_name\",        col(\"prod_company.name\"))\n",
        "    .withColumn(\"company_founded\",     col(\"prod_company.founded\"))\n",
        "    .drop(\"prod_company\").drop(\"metadata\")\n",
        ")\n",
        "\n",
        "# 7. Write flattened DataFrame out as Parquet\n",
        "PARQUET_PATH = \"/content/movies_flattened_parquet\"\n",
        "df_flat.write.mode(\"overwrite\").parquet(PARQUET_PATH)\n",
        "print(f\"➡️ Flattened data written to Parquet at {PARQUET_PATH}\")\n",
        "\n",
        "# 8. Register as an external Parquet table in Spark SQL\n",
        "spark.sql(f\"\"\"\n",
        "  CREATE TABLE IF NOT EXISTS movies_external\n",
        "  USING PARQUET\n",
        "  OPTIONS (path '{PARQUET_PATH}')\n",
        "\"\"\")\n",
        "print(\"✅ External Parquet table 'movies_external' is ready in Spark SQL.\")\n",
        "\n",
        "# (Optional) Preview\n",
        "spark.sql(\"SELECT * FROM movies_external LIMIT 5\").show(truncate=False)\n"
      ]
    }
  ]
}